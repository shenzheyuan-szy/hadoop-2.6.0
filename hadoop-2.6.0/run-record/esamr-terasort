slave3:
slave1:
slave17:
slave15:
slave18:
slave2:
slave6:
slave20:
slave16:
slave10:
slave19:
slave5:
slave13:
slave4:
slave12:
slave11:
    Minion did not return. [Not connected]
slave9:
    Minion did not return. [Not connected]
slave14:
    Minion did not return. [Not connected]
slave8:
    Minion did not return. [Not connected]
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
20/11/10 15:08:02 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
20/11/10 15:08:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
rmr: `/terasort-output/0': Input/output error
rmr: File does not exist: hdfs://master:9000/terasort-output/0
20/11/10 15:08:04 INFO terasort.TeraSort: starting
20/11/10 15:08:04 INFO terasort.TeraSort: starting
20/11/10 15:08:04 INFO terasort.TeraSort: starting
20/11/10 15:08:05 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 15:08:05 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 15:08:06 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 15:08:06 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4360745): File does not exist. Holder DFSClient_NONMAPREDUCE_-1604017928_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 15:08:06 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4360745): File does not exist. Holder DFSClient_NONMAPREDUCE_-1604017928_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

20/11/10 15:08:06 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4360746): File does not exist. Holder DFSClient_NONMAPREDUCE_-1267295304_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 15:08:06 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4360746): File does not exist. Holder DFSClient_NONMAPREDUCE_-1267295304_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)


real	0m3.198s
user	0m4.872s
sys	0m0.376s

real	0m3.303s
user	0m5.060s
sys	0m0.364s
20/11/10 15:08:07 INFO client.RMProxy: Connecting to ResourceManager at master/10.0.0.27:8032
20/11/10 15:08:09 INFO mapreduce.JobSubmitter: number of splits:448
20/11/10 15:08:09 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
20/11/10 15:08:09 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
20/11/10 15:08:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1603168482046_0037
20/11/10 15:08:09 INFO impl.YarnClientImpl: Submitted application application_1603168482046_0037
20/11/10 15:08:09 INFO mapreduce.Job: The url to track the job: http://master:50030/proxy/application_1603168482046_0037/
20/11/10 15:08:09 INFO mapreduce.Job: Running job: job_1603168482046_0037
20/11/10 15:08:21 INFO mapreduce.Job: Job job_1603168482046_0037 running in uber mode : false
20/11/10 15:08:21 INFO mapreduce.Job:  map 0% reduce 0%
20/11/10 15:08:32 INFO mapreduce.Job:  map 1% reduce 0%
20/11/10 15:08:34 INFO mapreduce.Job:  map 2% reduce 0%
20/11/10 15:08:35 INFO mapreduce.Job:  map 3% reduce 0%
20/11/10 15:08:36 INFO mapreduce.Job:  map 4% reduce 0%
20/11/10 15:08:37 INFO mapreduce.Job:  map 6% reduce 0%
20/11/10 15:08:38 INFO mapreduce.Job:  map 10% reduce 0%
20/11/10 15:08:39 INFO mapreduce.Job:  map 12% reduce 0%
20/11/10 15:08:40 INFO mapreduce.Job:  map 14% reduce 0%
20/11/10 15:08:41 INFO mapreduce.Job:  map 17% reduce 0%
20/11/10 15:08:42 INFO mapreduce.Job:  map 18% reduce 0%
20/11/10 15:08:43 INFO mapreduce.Job:  map 19% reduce 0%
20/11/10 15:08:44 INFO mapreduce.Job:  map 20% reduce 0%
20/11/10 15:08:45 INFO mapreduce.Job:  map 21% reduce 0%
20/11/10 15:08:46 INFO mapreduce.Job:  map 22% reduce 0%
20/11/10 15:08:47 INFO mapreduce.Job:  map 23% reduce 0%
20/11/10 15:08:48 INFO mapreduce.Job:  map 26% reduce 0%
20/11/10 15:08:49 INFO mapreduce.Job:  map 29% reduce 0%
20/11/10 15:08:50 INFO mapreduce.Job:  map 31% reduce 0%
20/11/10 15:08:51 INFO mapreduce.Job:  map 33% reduce 0%
20/11/10 15:08:52 INFO mapreduce.Job:  map 35% reduce 0%
20/11/10 15:08:53 INFO mapreduce.Job:  map 37% reduce 0%
20/11/10 15:08:55 INFO mapreduce.Job:  map 41% reduce 0%
20/11/10 15:08:56 INFO mapreduce.Job:  map 43% reduce 0%
20/11/10 15:08:57 INFO mapreduce.Job:  map 46% reduce 0%
20/11/10 15:08:58 INFO mapreduce.Job:  map 48% reduce 0%
20/11/10 15:08:59 INFO mapreduce.Job:  map 50% reduce 0%
20/11/10 15:09:00 INFO mapreduce.Job:  map 52% reduce 0%
20/11/10 15:09:01 INFO mapreduce.Job:  map 53% reduce 0%
20/11/10 15:09:02 INFO mapreduce.Job:  map 56% reduce 0%
20/11/10 15:09:03 INFO mapreduce.Job:  map 58% reduce 0%
20/11/10 15:09:05 INFO mapreduce.Job:  map 60% reduce 0%
20/11/10 15:09:06 INFO mapreduce.Job:  map 62% reduce 0%
20/11/10 15:09:07 INFO mapreduce.Job:  map 65% reduce 0%
20/11/10 15:09:08 INFO mapreduce.Job:  map 69% reduce 0%
20/11/10 15:09:09 INFO mapreduce.Job:  map 70% reduce 0%
20/11/10 15:09:10 INFO mapreduce.Job:  map 71% reduce 0%
20/11/10 15:09:11 INFO mapreduce.Job:  map 72% reduce 0%
20/11/10 15:09:12 INFO mapreduce.Job:  map 73% reduce 0%
20/11/10 15:09:13 INFO mapreduce.Job:  map 76% reduce 0%
20/11/10 15:09:15 INFO mapreduce.Job:  map 77% reduce 0%
20/11/10 15:09:16 INFO mapreduce.Job:  map 78% reduce 0%
20/11/10 15:09:17 INFO mapreduce.Job:  map 79% reduce 0%
20/11/10 15:09:19 INFO mapreduce.Job:  map 82% reduce 0%
20/11/10 15:09:20 INFO mapreduce.Job:  map 83% reduce 0%
20/11/10 15:09:22 INFO mapreduce.Job:  map 86% reduce 0%
20/11/10 15:09:23 INFO mapreduce.Job:  map 87% reduce 0%
20/11/10 15:09:32 INFO mapreduce.Job:  map 90% reduce 0%
20/11/10 15:09:33 INFO mapreduce.Job:  map 91% reduce 0%
20/11/10 15:09:35 INFO mapreduce.Job:  map 92% reduce 0%
20/11/10 15:09:36 INFO mapreduce.Job:  map 95% reduce 0%
20/11/10 15:09:37 INFO mapreduce.Job:  map 96% reduce 0%
20/11/10 15:09:38 INFO mapreduce.Job:  map 97% reduce 0%
20/11/10 15:09:41 INFO mapreduce.Job:  map 98% reduce 0%
20/11/10 15:09:43 INFO mapreduce.Job:  map 99% reduce 0%
20/11/10 15:09:48 INFO mapreduce.Job:  map 100% reduce 0%
20/11/10 15:10:09 INFO mapreduce.Job:  map 100% reduce 3%
20/11/10 15:10:10 INFO mapreduce.Job:  map 100% reduce 5%
20/11/10 15:10:11 INFO mapreduce.Job:  map 100% reduce 7%
20/11/10 15:10:12 INFO mapreduce.Job:  map 100% reduce 9%
20/11/10 15:10:14 INFO mapreduce.Job:  map 100% reduce 10%
20/11/10 15:10:15 INFO mapreduce.Job:  map 100% reduce 11%
20/11/10 15:10:16 INFO mapreduce.Job:  map 100% reduce 12%
20/11/10 15:10:18 INFO mapreduce.Job:  map 100% reduce 14%
20/11/10 15:10:20 INFO mapreduce.Job:  map 100% reduce 15%
20/11/10 15:10:22 INFO mapreduce.Job:  map 100% reduce 16%
20/11/10 15:10:23 INFO mapreduce.Job:  map 100% reduce 17%
20/11/10 15:10:24 INFO mapreduce.Job:  map 100% reduce 18%
20/11/10 15:10:25 INFO mapreduce.Job:  map 100% reduce 19%
20/11/10 15:10:26 INFO mapreduce.Job:  map 100% reduce 20%
20/11/10 15:10:27 INFO mapreduce.Job:  map 100% reduce 21%
20/11/10 15:10:28 INFO mapreduce.Job:  map 100% reduce 22%
20/11/10 15:10:29 INFO mapreduce.Job:  map 100% reduce 23%
20/11/10 15:10:30 INFO mapreduce.Job:  map 100% reduce 24%
20/11/10 15:10:31 INFO mapreduce.Job:  map 100% reduce 25%
20/11/10 15:10:33 INFO mapreduce.Job:  map 100% reduce 26%
20/11/10 15:10:34 INFO mapreduce.Job:  map 100% reduce 27%
20/11/10 15:10:35 INFO mapreduce.Job:  map 100% reduce 28%
20/11/10 15:10:36 INFO mapreduce.Job:  map 100% reduce 29%
20/11/10 15:10:37 INFO mapreduce.Job:  map 100% reduce 30%
20/11/10 15:10:39 INFO mapreduce.Job:  map 100% reduce 31%
20/11/10 15:10:40 INFO mapreduce.Job:  map 100% reduce 33%
20/11/10 15:10:44 INFO mapreduce.Job:  map 100% reduce 39%
20/11/10 15:10:47 INFO mapreduce.Job:  map 100% reduce 53%
20/11/10 15:10:50 INFO mapreduce.Job:  map 100% reduce 63%
20/11/10 15:10:51 INFO mapreduce.Job:  map 100% reduce 64%
20/11/10 15:10:53 INFO mapreduce.Job:  map 100% reduce 75%
20/11/10 15:10:54 INFO mapreduce.Job:  map 100% reduce 76%
20/11/10 15:10:56 INFO mapreduce.Job:  map 100% reduce 81%
20/11/10 15:10:57 INFO mapreduce.Job:  map 100% reduce 82%
20/11/10 15:10:59 INFO mapreduce.Job:  map 100% reduce 87%
20/11/10 15:11:00 INFO mapreduce.Job:  map 100% reduce 88%
20/11/10 15:11:02 INFO mapreduce.Job:  map 100% reduce 91%
20/11/10 15:11:05 INFO mapreduce.Job:  map 100% reduce 95%
20/11/10 15:11:08 INFO mapreduce.Job:  map 100% reduce 97%
20/11/10 15:11:13 INFO mapreduce.Job:  map 100% reduce 98%
20/11/10 15:11:15 INFO mapreduce.Job:  map 100% reduce 99%
20/11/10 15:11:20 INFO mapreduce.Job:  map 100% reduce 100%
20/11/10 15:11:35 INFO mapreduce.Job: Job job_1603168482046_0037 completed successfully
20/11/10 15:11:35 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=31200292918
		FILE: Number of bytes written=62455460214
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=30000047488
		HDFS: Number of bytes written=30000000000
		HDFS: Number of read operations=1524
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=120
	Job Counters 
		Launched map tasks=448
		Launched reduce tasks=60
		Data-local map tasks=436
		Rack-local map tasks=12
		Total time spent by all maps in occupied slots (ms)=6058981
		Total time spent by all reduces in occupied slots (ms)=3875706
		Total time spent by all map tasks (ms)=6058981
		Total time spent by all reduce tasks (ms)=3875706
		Total vcore-seconds taken by all map tasks=6058981
		Total vcore-seconds taken by all reduce tasks=3875706
		Total megabyte-seconds taken by all map tasks=6204396544
		Total megabyte-seconds taken by all reduce tasks=3968722944
	Map-Reduce Framework
		Map input records=300000000
		Map output records=300000000
		Map output bytes=30600000000
		Map output materialized bytes=31200161280
		Input split bytes=47488
		Combine input records=0
		Combine output records=0
		Reduce input groups=300000000
		Reduce shuffle bytes=31200161280
		Reduce input records=300000000
		Reduce output records=300000000
		Spilled Records=600000000
		Shuffled Maps =26880
		Failed Shuffles=0
		Merged Map outputs=26880
		GC time elapsed (ms)=123612
		CPU time spent (ms)=3424050
		Physical memory (bytes) snapshot=133389111296
		Virtual memory (bytes) snapshot=528298487808
		Total committed heap usage (bytes)=101049171968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=30000000000
	File Output Format Counters 
		Bytes Written=30000000000
20/11/10 15:11:35 INFO terasort.TeraSort: done

real	3m32.817s
user	0m9.569s
sys	0m0.676s
slave17:
slave15:
slave20:
slave3:
slave1:
slave13:
slave18:
slave19:
slave6:
slave16:
slave2:
slave5:
slave12:
slave10:
slave4:
slave11:
    Minion did not return. [Not connected]
slave9:
    Minion did not return. [Not connected]
slave14:
    Minion did not return. [Not connected]
slave8:
    Minion did not return. [Not connected]
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
20/11/10 15:14:34 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
rmr: `/terasort-output/0': No such file or directory
rmr: `/terasort-output/0': No such file or directory
20/11/10 15:14:35 INFO terasort.TeraSort: starting
20/11/10 15:14:35 INFO terasort.TeraSort: starting
20/11/10 15:14:35 INFO terasort.TeraSort: starting
20/11/10 15:14:36 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 15:14:36 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 15:14:36 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 15:14:37 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4360885): File does not exist. Holder DFSClient_NONMAPREDUCE_134025700_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 15:14:37 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4360885): File does not exist. Holder DFSClient_NONMAPREDUCE_134025700_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

20/11/10 15:14:37 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4360886): File does not exist. Holder DFSClient_NONMAPREDUCE_-1984745166_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 15:14:37 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4360886): File does not exist. Holder DFSClient_NONMAPREDUCE_-1984745166_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)


real	0m3.510s
user	0m5.720s
sys	0m0.336s

real	0m3.551s
user	0m5.564s
sys	0m0.352s
20/11/10 15:14:38 INFO client.RMProxy: Connecting to ResourceManager at master/10.0.0.27:8032
20/11/10 15:14:40 INFO mapreduce.JobSubmitter: number of splits:448
20/11/10 15:14:40 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
20/11/10 15:14:40 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
20/11/10 15:14:40 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1603168482046_0038
20/11/10 15:14:40 INFO impl.YarnClientImpl: Submitted application application_1603168482046_0038
20/11/10 15:14:40 INFO mapreduce.Job: The url to track the job: http://master:50030/proxy/application_1603168482046_0038/
20/11/10 15:14:40 INFO mapreduce.Job: Running job: job_1603168482046_0038
20/11/10 15:14:51 INFO mapreduce.Job: Job job_1603168482046_0038 running in uber mode : false
20/11/10 15:14:51 INFO mapreduce.Job:  map 0% reduce 0%
20/11/10 15:15:00 INFO mapreduce.Job:  map 1% reduce 0%
20/11/10 15:15:04 INFO mapreduce.Job:  map 2% reduce 0%
20/11/10 15:15:05 INFO mapreduce.Job:  map 4% reduce 0%
20/11/10 15:15:07 INFO mapreduce.Job:  map 5% reduce 0%
20/11/10 15:15:08 INFO mapreduce.Job:  map 8% reduce 0%
20/11/10 15:15:09 INFO mapreduce.Job:  map 11% reduce 0%
20/11/10 15:15:10 INFO mapreduce.Job:  map 13% reduce 0%
20/11/10 15:15:11 INFO mapreduce.Job:  map 15% reduce 0%
20/11/10 15:15:12 INFO mapreduce.Job:  map 17% reduce 0%
20/11/10 15:15:13 INFO mapreduce.Job:  map 18% reduce 0%
20/11/10 15:15:14 INFO mapreduce.Job:  map 19% reduce 0%
20/11/10 15:15:15 INFO mapreduce.Job:  map 20% reduce 0%
20/11/10 15:15:16 INFO mapreduce.Job:  map 23% reduce 0%
20/11/10 15:15:17 INFO mapreduce.Job:  map 24% reduce 0%
20/11/10 15:15:18 INFO mapreduce.Job:  map 25% reduce 0%
20/11/10 15:15:19 INFO mapreduce.Job:  map 28% reduce 0%
20/11/10 15:15:20 INFO mapreduce.Job:  map 30% reduce 0%
20/11/10 15:15:21 INFO mapreduce.Job:  map 33% reduce 0%
20/11/10 15:15:22 INFO mapreduce.Job:  map 36% reduce 0%
20/11/10 15:15:23 INFO mapreduce.Job:  map 38% reduce 0%
20/11/10 15:15:24 INFO mapreduce.Job:  map 39% reduce 0%
20/11/10 15:15:25 INFO mapreduce.Job:  map 42% reduce 0%
20/11/10 15:15:26 INFO mapreduce.Job:  map 43% reduce 0%
20/11/10 15:15:27 INFO mapreduce.Job:  map 47% reduce 0%
20/11/10 15:15:28 INFO mapreduce.Job:  map 49% reduce 0%
20/11/10 15:15:29 INFO mapreduce.Job:  map 51% reduce 0%
20/11/10 15:15:30 INFO mapreduce.Job:  map 53% reduce 0%
20/11/10 15:15:31 INFO mapreduce.Job:  map 56% reduce 0%
20/11/10 15:15:32 INFO mapreduce.Job:  map 58% reduce 0%
20/11/10 15:15:34 INFO mapreduce.Job:  map 61% reduce 0%
20/11/10 15:15:35 INFO mapreduce.Job:  map 62% reduce 0%
20/11/10 15:15:36 INFO mapreduce.Job:  map 66% reduce 0%
20/11/10 15:15:37 INFO mapreduce.Job:  map 67% reduce 0%
20/11/10 15:15:38 INFO mapreduce.Job:  map 68% reduce 0%
20/11/10 15:15:39 INFO mapreduce.Job:  map 69% reduce 0%
20/11/10 15:15:40 INFO mapreduce.Job:  map 71% reduce 0%
20/11/10 15:15:41 INFO mapreduce.Job:  map 74% reduce 0%
20/11/10 15:15:42 INFO mapreduce.Job:  map 76% reduce 0%
20/11/10 15:15:44 INFO mapreduce.Job:  map 79% reduce 0%
20/11/10 15:15:45 INFO mapreduce.Job:  map 80% reduce 0%
20/11/10 15:15:46 INFO mapreduce.Job:  map 81% reduce 0%
20/11/10 15:15:47 INFO mapreduce.Job:  map 82% reduce 0%
20/11/10 15:15:48 INFO mapreduce.Job:  map 83% reduce 0%
20/11/10 15:15:49 INFO mapreduce.Job:  map 84% reduce 0%
20/11/10 15:15:52 INFO mapreduce.Job:  map 87% reduce 0%
20/11/10 15:15:54 INFO mapreduce.Job:  map 88% reduce 0%
20/11/10 15:15:55 INFO mapreduce.Job:  map 90% reduce 0%
20/11/10 15:15:56 INFO mapreduce.Job:  map 91% reduce 0%
20/11/10 15:15:57 INFO mapreduce.Job:  map 92% reduce 0%
20/11/10 15:15:58 INFO mapreduce.Job:  map 93% reduce 0%
20/11/10 15:15:59 INFO mapreduce.Job:  map 94% reduce 0%
20/11/10 15:16:01 INFO mapreduce.Job:  map 95% reduce 0%
20/11/10 15:16:03 INFO mapreduce.Job:  map 96% reduce 0%
20/11/10 15:16:06 INFO mapreduce.Job:  map 97% reduce 0%
20/11/10 15:16:09 INFO mapreduce.Job:  map 98% reduce 0%
20/11/10 15:16:10 INFO mapreduce.Job:  map 99% reduce 0%
20/11/10 15:16:14 INFO mapreduce.Job:  map 100% reduce 0%
20/11/10 15:16:29 INFO mapreduce.Job:  map 100% reduce 2%
20/11/10 15:16:30 INFO mapreduce.Job:  map 100% reduce 3%
20/11/10 15:16:31 INFO mapreduce.Job:  map 100% reduce 6%
20/11/10 15:16:32 INFO mapreduce.Job:  map 100% reduce 7%
20/11/10 15:16:33 INFO mapreduce.Job:  map 100% reduce 8%
20/11/10 15:16:34 INFO mapreduce.Job:  map 100% reduce 9%
20/11/10 15:16:35 INFO mapreduce.Job:  map 100% reduce 10%
20/11/10 15:16:36 INFO mapreduce.Job:  map 100% reduce 11%
20/11/10 15:16:37 INFO mapreduce.Job:  map 100% reduce 12%
20/11/10 15:16:38 INFO mapreduce.Job:  map 100% reduce 13%
20/11/10 15:16:39 INFO mapreduce.Job:  map 100% reduce 14%
20/11/10 15:16:41 INFO mapreduce.Job:  map 100% reduce 15%
20/11/10 15:16:42 INFO mapreduce.Job:  map 100% reduce 17%
20/11/10 15:16:44 INFO mapreduce.Job:  map 100% reduce 18%
20/11/10 15:16:45 INFO mapreduce.Job:  map 100% reduce 19%
20/11/10 15:16:46 INFO mapreduce.Job:  map 100% reduce 20%
20/11/10 15:16:47 INFO mapreduce.Job:  map 100% reduce 21%
20/11/10 15:16:48 INFO mapreduce.Job:  map 100% reduce 22%
20/11/10 15:16:49 INFO mapreduce.Job:  map 100% reduce 23%
20/11/10 15:16:51 INFO mapreduce.Job:  map 100% reduce 24%
20/11/10 15:16:52 INFO mapreduce.Job:  map 100% reduce 25%
20/11/10 15:16:53 INFO mapreduce.Job:  map 100% reduce 26%
20/11/10 15:16:54 INFO mapreduce.Job:  map 100% reduce 27%
20/11/10 15:16:55 INFO mapreduce.Job:  map 100% reduce 28%
20/11/10 15:16:56 INFO mapreduce.Job:  map 100% reduce 29%
20/11/10 15:16:57 INFO mapreduce.Job:  map 100% reduce 30%
20/11/10 15:16:58 INFO mapreduce.Job:  map 100% reduce 32%
20/11/10 15:17:00 INFO mapreduce.Job:  map 100% reduce 33%
20/11/10 15:17:01 INFO mapreduce.Job:  map 100% reduce 35%
20/11/10 15:17:02 INFO mapreduce.Job:  map 100% reduce 36%
20/11/10 15:17:03 INFO mapreduce.Job:  map 100% reduce 39%
20/11/10 15:17:04 INFO mapreduce.Job:  map 100% reduce 43%
20/11/10 15:17:05 INFO mapreduce.Job:  map 100% reduce 45%
20/11/10 15:17:06 INFO mapreduce.Job:  map 100% reduce 49%
20/11/10 15:17:07 INFO mapreduce.Job:  map 100% reduce 58%
20/11/10 15:17:08 INFO mapreduce.Job:  map 100% reduce 61%
20/11/10 15:17:10 INFO mapreduce.Job:  map 100% reduce 71%
20/11/10 15:17:15 INFO mapreduce.Job:  map 100% reduce 82%
20/11/10 15:17:16 INFO mapreduce.Job:  map 100% reduce 83%
20/11/10 15:17:18 INFO mapreduce.Job:  map 100% reduce 94%
20/11/10 15:17:21 INFO mapreduce.Job:  map 100% reduce 96%
20/11/10 15:17:24 INFO mapreduce.Job:  map 100% reduce 97%
20/11/10 15:17:30 INFO mapreduce.Job:  map 100% reduce 98%
20/11/10 15:17:33 INFO mapreduce.Job:  map 100% reduce 99%
20/11/10 15:17:39 INFO mapreduce.Job:  map 100% reduce 100%
20/11/10 15:17:47 INFO mapreduce.Job: Job job_1603168482046_0038 completed successfully
20/11/10 15:17:47 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=31200292918
		FILE: Number of bytes written=62455460214
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=30000047488
		HDFS: Number of bytes written=30000000000
		HDFS: Number of read operations=1524
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=120
	Job Counters 
		Launched map tasks=448
		Launched reduce tasks=60
		Data-local map tasks=436
		Rack-local map tasks=12
		Total time spent by all maps in occupied slots (ms)=5609830
		Total time spent by all reduces in occupied slots (ms)=3683771
		Total time spent by all map tasks (ms)=5609830
		Total time spent by all reduce tasks (ms)=3683771
		Total vcore-seconds taken by all map tasks=5609830
		Total vcore-seconds taken by all reduce tasks=3683771
		Total megabyte-seconds taken by all map tasks=5744465920
		Total megabyte-seconds taken by all reduce tasks=3772181504
	Map-Reduce Framework
		Map input records=300000000
		Map output records=300000000
		Map output bytes=30600000000
		Map output materialized bytes=31200161280
		Input split bytes=47488
		Combine input records=0
		Combine output records=0
		Reduce input groups=300000000
		Reduce shuffle bytes=31200161280
		Reduce input records=300000000
		Reduce output records=300000000
		Spilled Records=600000000
		Shuffled Maps =26880
		Failed Shuffles=0
		Merged Map outputs=26880
		GC time elapsed (ms)=122014
		CPU time spent (ms)=3403980
		Physical memory (bytes) snapshot=133361274880
		Virtual memory (bytes) snapshot=528392687616
		Total committed heap usage (bytes)=101022957568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=30000000000
	File Output Format Counters 
		Bytes Written=30000000000
20/11/10 15:17:47 INFO terasort.TeraSort: done

real	3m13.617s
user	0m8.801s
sys	0m0.652s
slave15:
slave3:
slave17:
slave1:
slave18:
slave20:
slave16:
slave19:
slave2:
slave12:
slave10:
slave6:
slave13:
slave5:
slave4:
slave11:
    Minion did not return. [Not connected]
slave9:
    Minion did not return. [Not connected]
slave14:
    Minion did not return. [Not connected]
slave8:
    Minion did not return. [Not connected]
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
20/11/10 15:22:41 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
20/11/10 15:22:41 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
rmr: `/terasort-output/0': Input/output error
rmr: `/terasort-output/0': No such file or directory
20/11/10 15:22:43 INFO terasort.TeraSort: starting
20/11/10 15:22:43 INFO terasort.TeraSort: starting
20/11/10 15:22:43 INFO terasort.TeraSort: starting
20/11/10 15:22:44 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 15:22:44 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 15:22:44 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 15:22:45 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4361026): File does not exist. Holder DFSClient_NONMAPREDUCE_651981415_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 15:22:45 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4361026): File does not exist. Holder DFSClient_NONMAPREDUCE_651981415_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

20/11/10 15:22:45 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4361025): File does not exist. Holder DFSClient_NONMAPREDUCE_1437340473_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 15:22:45 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4361025): File does not exist. Holder DFSClient_NONMAPREDUCE_1437340473_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)


real	0m3.762s
user	0m5.400s
sys	0m0.312s

real	0m3.910s
user	0m5.568s
sys	0m0.500s
20/11/10 15:22:46 INFO client.RMProxy: Connecting to ResourceManager at master/10.0.0.27:8032
20/11/10 15:22:48 INFO mapreduce.JobSubmitter: number of splits:448
20/11/10 15:22:48 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
20/11/10 15:22:48 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
20/11/10 15:22:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1603168482046_0039
20/11/10 15:22:48 INFO impl.YarnClientImpl: Submitted application application_1603168482046_0039
20/11/10 15:22:48 INFO mapreduce.Job: The url to track the job: http://master:50030/proxy/application_1603168482046_0039/
20/11/10 15:22:48 INFO mapreduce.Job: Running job: job_1603168482046_0039
20/11/10 15:23:00 INFO mapreduce.Job: Job job_1603168482046_0039 running in uber mode : false
20/11/10 15:23:00 INFO mapreduce.Job:  map 0% reduce 0%
20/11/10 15:23:10 INFO mapreduce.Job:  map 1% reduce 0%
20/11/10 15:23:12 INFO mapreduce.Job:  map 2% reduce 0%
20/11/10 15:23:13 INFO mapreduce.Job:  map 3% reduce 0%
20/11/10 15:23:15 INFO mapreduce.Job:  map 4% reduce 0%
20/11/10 15:23:16 INFO mapreduce.Job:  map 6% reduce 0%
20/11/10 15:23:17 INFO mapreduce.Job:  map 11% reduce 0%
20/11/10 15:23:18 INFO mapreduce.Job:  map 12% reduce 0%
20/11/10 15:23:19 INFO mapreduce.Job:  map 14% reduce 0%
20/11/10 15:23:20 INFO mapreduce.Job:  map 17% reduce 0%
20/11/10 15:23:21 INFO mapreduce.Job:  map 19% reduce 0%
20/11/10 15:23:22 INFO mapreduce.Job:  map 20% reduce 0%
20/11/10 15:23:24 INFO mapreduce.Job:  map 21% reduce 0%
20/11/10 15:23:25 INFO mapreduce.Job:  map 23% reduce 0%
20/11/10 15:23:27 INFO mapreduce.Job:  map 26% reduce 0%
20/11/10 15:23:28 INFO mapreduce.Job:  map 29% reduce 0%
20/11/10 15:23:29 INFO mapreduce.Job:  map 30% reduce 0%
20/11/10 15:23:30 INFO mapreduce.Job:  map 33% reduce 0%
20/11/10 15:23:31 INFO mapreduce.Job:  map 34% reduce 0%
20/11/10 15:23:32 INFO mapreduce.Job:  map 38% reduce 0%
20/11/10 15:23:33 INFO mapreduce.Job:  map 40% reduce 0%
20/11/10 15:23:34 INFO mapreduce.Job:  map 41% reduce 0%
20/11/10 15:23:35 INFO mapreduce.Job:  map 44% reduce 0%
20/11/10 15:23:36 INFO mapreduce.Job:  map 46% reduce 0%
20/11/10 15:23:37 INFO mapreduce.Job:  map 49% reduce 0%
20/11/10 15:23:38 INFO mapreduce.Job:  map 51% reduce 0%
20/11/10 15:23:39 INFO mapreduce.Job:  map 52% reduce 0%
20/11/10 15:23:40 INFO mapreduce.Job:  map 53% reduce 0%
20/11/10 15:23:41 INFO mapreduce.Job:  map 57% reduce 0%
20/11/10 15:23:42 INFO mapreduce.Job:  map 60% reduce 0%
20/11/10 15:23:43 INFO mapreduce.Job:  map 61% reduce 0%
20/11/10 15:23:44 INFO mapreduce.Job:  map 64% reduce 0%
20/11/10 15:23:46 INFO mapreduce.Job:  map 66% reduce 0%
20/11/10 15:23:47 INFO mapreduce.Job:  map 67% reduce 0%
20/11/10 15:23:48 INFO mapreduce.Job:  map 69% reduce 0%
20/11/10 15:23:49 INFO mapreduce.Job:  map 71% reduce 0%
20/11/10 15:23:50 INFO mapreduce.Job:  map 74% reduce 0%
20/11/10 15:23:51 INFO mapreduce.Job:  map 75% reduce 0%
20/11/10 15:23:52 INFO mapreduce.Job:  map 76% reduce 0%
20/11/10 15:23:53 INFO mapreduce.Job:  map 78% reduce 0%
20/11/10 15:23:56 INFO mapreduce.Job:  map 80% reduce 0%
20/11/10 15:23:57 INFO mapreduce.Job:  map 81% reduce 0%
20/11/10 15:23:59 INFO mapreduce.Job:  map 84% reduce 0%
20/11/10 15:24:02 INFO mapreduce.Job:  map 85% reduce 0%
20/11/10 15:24:03 INFO mapreduce.Job:  map 87% reduce 0%
20/11/10 15:24:06 INFO mapreduce.Job:  map 89% reduce 0%
20/11/10 15:24:07 INFO mapreduce.Job:  map 90% reduce 0%
20/11/10 15:24:08 INFO mapreduce.Job:  map 91% reduce 0%
20/11/10 15:24:09 INFO mapreduce.Job:  map 92% reduce 0%
20/11/10 15:24:10 INFO mapreduce.Job:  map 93% reduce 0%
20/11/10 15:24:13 INFO mapreduce.Job:  map 94% reduce 0%
20/11/10 15:24:15 INFO mapreduce.Job:  map 95% reduce 0%
20/11/10 15:24:17 INFO mapreduce.Job:  map 96% reduce 0%
20/11/10 15:24:19 INFO mapreduce.Job:  map 97% reduce 0%
20/11/10 15:24:22 INFO mapreduce.Job:  map 98% reduce 0%
20/11/10 15:24:26 INFO mapreduce.Job:  map 99% reduce 0%
20/11/10 15:24:30 INFO mapreduce.Job:  map 100% reduce 0%
20/11/10 15:24:51 INFO mapreduce.Job:  map 100% reduce 1%
20/11/10 15:24:52 INFO mapreduce.Job:  map 100% reduce 3%
20/11/10 15:24:53 INFO mapreduce.Job:  map 100% reduce 5%
20/11/10 15:24:54 INFO mapreduce.Job:  map 100% reduce 7%
20/11/10 15:24:55 INFO mapreduce.Job:  map 100% reduce 9%
20/11/10 15:24:56 INFO mapreduce.Job:  map 100% reduce 10%
20/11/10 15:24:58 INFO mapreduce.Job:  map 100% reduce 11%
20/11/10 15:24:59 INFO mapreduce.Job:  map 100% reduce 12%
20/11/10 15:25:00 INFO mapreduce.Job:  map 100% reduce 13%
20/11/10 15:25:01 INFO mapreduce.Job:  map 100% reduce 14%
20/11/10 15:25:02 INFO mapreduce.Job:  map 100% reduce 15%
20/11/10 15:25:04 INFO mapreduce.Job:  map 100% reduce 16%
20/11/10 15:25:05 INFO mapreduce.Job:  map 100% reduce 17%
20/11/10 15:25:07 INFO mapreduce.Job:  map 100% reduce 19%
20/11/10 15:25:08 INFO mapreduce.Job:  map 100% reduce 20%
20/11/10 15:25:10 INFO mapreduce.Job:  map 100% reduce 21%
20/11/10 15:25:11 INFO mapreduce.Job:  map 100% reduce 22%
20/11/10 15:25:12 INFO mapreduce.Job:  map 100% reduce 23%
20/11/10 15:25:13 INFO mapreduce.Job:  map 100% reduce 24%
20/11/10 15:25:14 INFO mapreduce.Job:  map 100% reduce 25%
20/11/10 15:25:15 INFO mapreduce.Job:  map 100% reduce 26%
20/11/10 15:25:16 INFO mapreduce.Job:  map 100% reduce 27%
20/11/10 15:25:17 INFO mapreduce.Job:  map 100% reduce 28%
20/11/10 15:25:18 INFO mapreduce.Job:  map 100% reduce 29%
20/11/10 15:25:19 INFO mapreduce.Job:  map 100% reduce 31%
20/11/10 15:25:20 INFO mapreduce.Job:  map 100% reduce 32%
20/11/10 15:25:22 INFO mapreduce.Job:  map 100% reduce 34%
20/11/10 15:25:23 INFO mapreduce.Job:  map 100% reduce 36%
20/11/10 15:25:24 INFO mapreduce.Job:  map 100% reduce 37%
20/11/10 15:25:25 INFO mapreduce.Job:  map 100% reduce 40%
20/11/10 15:25:26 INFO mapreduce.Job:  map 100% reduce 41%
20/11/10 15:25:27 INFO mapreduce.Job:  map 100% reduce 43%
20/11/10 15:25:28 INFO mapreduce.Job:  map 100% reduce 50%
20/11/10 15:25:29 INFO mapreduce.Job:  map 100% reduce 58%
20/11/10 15:25:30 INFO mapreduce.Job:  map 100% reduce 60%
20/11/10 15:25:32 INFO mapreduce.Job:  map 100% reduce 74%
20/11/10 15:25:33 INFO mapreduce.Job:  map 100% reduce 76%
20/11/10 15:25:35 INFO mapreduce.Job:  map 100% reduce 84%
20/11/10 15:25:36 INFO mapreduce.Job:  map 100% reduce 85%
20/11/10 15:25:37 INFO mapreduce.Job:  map 100% reduce 86%
20/11/10 15:25:38 INFO mapreduce.Job:  map 100% reduce 89%
20/11/10 15:25:39 INFO mapreduce.Job:  map 100% reduce 90%
20/11/10 15:25:41 INFO mapreduce.Job:  map 100% reduce 93%
20/11/10 15:25:44 INFO mapreduce.Job:  map 100% reduce 96%
20/11/10 15:25:48 INFO mapreduce.Job:  map 100% reduce 99%
20/11/10 15:25:51 INFO mapreduce.Job:  map 100% reduce 100%
20/11/10 15:26:02 INFO mapreduce.Job: Job job_1603168482046_0039 completed successfully
20/11/10 15:26:02 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=31200292918
		FILE: Number of bytes written=62455460214
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=30000047488
		HDFS: Number of bytes written=30000000000
		HDFS: Number of read operations=1524
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=120
	Job Counters 
		Launched map tasks=448
		Launched reduce tasks=60
		Data-local map tasks=433
		Rack-local map tasks=15
		Total time spent by all maps in occupied slots (ms)=5942751
		Total time spent by all reduces in occupied slots (ms)=3528003
		Total time spent by all map tasks (ms)=5942751
		Total time spent by all reduce tasks (ms)=3528003
		Total vcore-seconds taken by all map tasks=5942751
		Total vcore-seconds taken by all reduce tasks=3528003
		Total megabyte-seconds taken by all map tasks=6085377024
		Total megabyte-seconds taken by all reduce tasks=3612675072
	Map-Reduce Framework
		Map input records=300000000
		Map output records=300000000
		Map output bytes=30600000000
		Map output materialized bytes=31200161280
		Input split bytes=47488
		Combine input records=0
		Combine output records=0
		Reduce input groups=300000000
		Reduce shuffle bytes=31200161280
		Reduce input records=300000000
		Reduce output records=300000000
		Spilled Records=600000000
		Shuffled Maps =26880
		Failed Shuffles=0
		Merged Map outputs=26880
		GC time elapsed (ms)=122361
		CPU time spent (ms)=3420430
		Physical memory (bytes) snapshot=133418512384
		Virtual memory (bytes) snapshot=528265596928
		Total committed heap usage (bytes)=100996743168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=30000000000
	File Output Format Counters 
		Bytes Written=30000000000
20/11/10 15:26:02 INFO terasort.TeraSort: done

real	3m20.737s
user	0m9.205s
sys	0m0.632s
