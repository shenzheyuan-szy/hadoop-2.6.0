slave1:
slave17:
slave18:
slave20:
slave15:
slave4:
slave19:
slave3:
slave2:
slave5:
slave16:
slave12:
slave13:
slave6:
slave10:
slave11:
    Minion did not return. [Not connected]
slave9:
    Minion did not return. [Not connected]
slave14:
    Minion did not return. [Not connected]
slave8:
    Minion did not return. [Not connected]
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
20/11/10 14:29:37 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
rmr: File does not exist: hdfs://master:9000/terasort-output/0
rmr: File does not exist: hdfs://master:9000/terasort-output/0
20/11/10 14:29:39 INFO terasort.TeraSort: starting
20/11/10 14:29:39 INFO terasort.TeraSort: starting
20/11/10 14:29:39 INFO terasort.TeraSort: starting
20/11/10 14:29:40 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 14:29:40 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 14:29:41 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 14:29:41 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4360325): File does not exist. Holder DFSClient_NONMAPREDUCE_-1735168521_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 14:29:41 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4360325): File does not exist. Holder DFSClient_NONMAPREDUCE_-1735168521_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

20/11/10 14:29:41 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4360326): File does not exist. Holder DFSClient_NONMAPREDUCE_-1611020704_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 14:29:41 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4360326): File does not exist. Holder DFSClient_NONMAPREDUCE_-1611020704_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)


real	0m3.369s
user	0m5.328s
sys	0m0.424s

real	0m3.498s
user	0m5.432s
sys	0m0.396s
20/11/10 14:29:42 INFO client.RMProxy: Connecting to ResourceManager at master/10.0.0.27:8032
20/11/10 14:29:43 INFO mapreduce.JobSubmitter: number of splits:448
20/11/10 14:29:43 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
20/11/10 14:29:43 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
20/11/10 14:29:43 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1603168482046_0034
20/11/10 14:29:43 INFO impl.YarnClientImpl: Submitted application application_1603168482046_0034
20/11/10 14:29:43 INFO mapreduce.Job: The url to track the job: http://master:50030/proxy/application_1603168482046_0034/
20/11/10 14:29:43 INFO mapreduce.Job: Running job: job_1603168482046_0034
20/11/10 14:29:54 INFO mapreduce.Job: Job job_1603168482046_0034 running in uber mode : false
20/11/10 14:29:54 INFO mapreduce.Job:  map 0% reduce 0%
20/11/10 14:30:03 INFO mapreduce.Job:  map 1% reduce 0%
20/11/10 14:30:05 INFO mapreduce.Job:  map 2% reduce 0%
20/11/10 14:30:07 INFO mapreduce.Job:  map 3% reduce 0%
20/11/10 14:30:08 INFO mapreduce.Job:  map 4% reduce 0%
20/11/10 14:30:09 INFO mapreduce.Job:  map 7% reduce 0%
20/11/10 14:30:10 INFO mapreduce.Job:  map 10% reduce 0%
20/11/10 14:30:11 INFO mapreduce.Job:  map 12% reduce 0%
20/11/10 14:30:12 INFO mapreduce.Job:  map 13% reduce 0%
20/11/10 14:30:13 INFO mapreduce.Job:  map 15% reduce 0%
20/11/10 14:30:14 INFO mapreduce.Job:  map 18% reduce 0%
20/11/10 14:30:15 INFO mapreduce.Job:  map 19% reduce 0%
20/11/10 14:30:16 INFO mapreduce.Job:  map 20% reduce 0%
20/11/10 14:30:17 INFO mapreduce.Job:  map 21% reduce 0%
20/11/10 14:30:18 INFO mapreduce.Job:  map 23% reduce 0%
20/11/10 14:30:19 INFO mapreduce.Job:  map 25% reduce 0%
20/11/10 14:30:20 INFO mapreduce.Job:  map 26% reduce 0%
20/11/10 14:30:21 INFO mapreduce.Job:  map 29% reduce 0%
20/11/10 14:30:22 INFO mapreduce.Job:  map 31% reduce 0%
20/11/10 14:30:23 INFO mapreduce.Job:  map 34% reduce 0%
20/11/10 14:30:24 INFO mapreduce.Job:  map 36% reduce 0%
20/11/10 14:30:25 INFO mapreduce.Job:  map 39% reduce 0%
20/11/10 14:30:26 INFO mapreduce.Job:  map 40% reduce 0%
20/11/10 14:30:27 INFO mapreduce.Job:  map 43% reduce 0%
20/11/10 14:30:28 INFO mapreduce.Job:  map 45% reduce 0%
20/11/10 14:30:29 INFO mapreduce.Job:  map 48% reduce 0%
20/11/10 14:30:30 INFO mapreduce.Job:  map 50% reduce 0%
20/11/10 14:30:31 INFO mapreduce.Job:  map 52% reduce 0%
20/11/10 14:30:32 INFO mapreduce.Job:  map 54% reduce 0%
20/11/10 14:30:33 INFO mapreduce.Job:  map 55% reduce 0%
20/11/10 14:30:34 INFO mapreduce.Job:  map 57% reduce 0%
20/11/10 14:30:35 INFO mapreduce.Job:  map 58% reduce 0%
20/11/10 14:30:36 INFO mapreduce.Job:  map 60% reduce 0%
20/11/10 14:30:37 INFO mapreduce.Job:  map 62% reduce 0%
20/11/10 14:30:38 INFO mapreduce.Job:  map 63% reduce 0%
20/11/10 14:30:39 INFO mapreduce.Job:  map 66% reduce 0%
20/11/10 14:30:41 INFO mapreduce.Job:  map 68% reduce 0%
20/11/10 14:30:42 INFO mapreduce.Job:  map 70% reduce 0%
20/11/10 14:30:43 INFO mapreduce.Job:  map 73% reduce 0%
20/11/10 14:30:44 INFO mapreduce.Job:  map 74% reduce 0%
20/11/10 14:30:45 INFO mapreduce.Job:  map 75% reduce 0%
20/11/10 14:30:46 INFO mapreduce.Job:  map 76% reduce 0%
20/11/10 14:30:47 INFO mapreduce.Job:  map 77% reduce 0%
20/11/10 14:30:48 INFO mapreduce.Job:  map 78% reduce 0%
20/11/10 14:30:50 INFO mapreduce.Job:  map 80% reduce 0%
20/11/10 14:30:51 INFO mapreduce.Job:  map 82% reduce 0%
20/11/10 14:30:53 INFO mapreduce.Job:  map 84% reduce 0%
20/11/10 14:30:54 INFO mapreduce.Job:  map 85% reduce 0%
20/11/10 14:30:55 INFO mapreduce.Job:  map 86% reduce 0%
20/11/10 14:30:56 INFO mapreduce.Job:  map 87% reduce 0%
20/11/10 14:30:57 INFO mapreduce.Job:  map 88% reduce 0%
20/11/10 14:30:58 INFO mapreduce.Job:  map 89% reduce 0%
20/11/10 14:31:00 INFO mapreduce.Job:  map 91% reduce 0%
20/11/10 14:31:01 INFO mapreduce.Job:  map 92% reduce 0%
20/11/10 14:31:02 INFO mapreduce.Job:  map 93% reduce 0%
20/11/10 14:31:03 INFO mapreduce.Job:  map 94% reduce 0%
20/11/10 14:31:04 INFO mapreduce.Job:  map 95% reduce 0%
20/11/10 14:31:06 INFO mapreduce.Job:  map 96% reduce 0%
20/11/10 14:31:09 INFO mapreduce.Job:  map 97% reduce 0%
20/11/10 14:31:13 INFO mapreduce.Job:  map 98% reduce 0%
20/11/10 14:31:17 INFO mapreduce.Job:  map 99% reduce 0%
20/11/10 14:31:22 INFO mapreduce.Job:  map 100% reduce 0%
20/11/10 14:31:36 INFO mapreduce.Job:  map 100% reduce 2%
20/11/10 14:31:37 INFO mapreduce.Job:  map 100% reduce 5%
20/11/10 14:31:39 INFO mapreduce.Job:  map 100% reduce 8%
20/11/10 14:31:40 INFO mapreduce.Job:  map 100% reduce 9%
20/11/10 14:31:41 INFO mapreduce.Job:  map 100% reduce 10%
20/11/10 14:31:42 INFO mapreduce.Job:  map 100% reduce 11%
20/11/10 14:31:43 INFO mapreduce.Job:  map 100% reduce 12%
20/11/10 14:31:45 INFO mapreduce.Job:  map 100% reduce 14%
20/11/10 14:31:48 INFO mapreduce.Job:  map 100% reduce 15%
20/11/10 14:31:49 INFO mapreduce.Job:  map 100% reduce 16%
20/11/10 14:31:50 INFO mapreduce.Job:  map 100% reduce 17%
20/11/10 14:31:52 INFO mapreduce.Job:  map 100% reduce 19%
20/11/10 14:31:53 INFO mapreduce.Job:  map 100% reduce 20%
20/11/10 14:31:55 INFO mapreduce.Job:  map 100% reduce 22%
20/11/10 14:31:57 INFO mapreduce.Job:  map 100% reduce 23%
20/11/10 14:31:58 INFO mapreduce.Job:  map 100% reduce 24%
20/11/10 14:31:59 INFO mapreduce.Job:  map 100% reduce 26%
20/11/10 14:32:01 INFO mapreduce.Job:  map 100% reduce 28%
20/11/10 14:32:03 INFO mapreduce.Job:  map 100% reduce 29%
20/11/10 14:32:04 INFO mapreduce.Job:  map 100% reduce 31%
20/11/10 14:32:05 INFO mapreduce.Job:  map 100% reduce 32%
20/11/10 14:32:06 INFO mapreduce.Job:  map 100% reduce 33%
20/11/10 14:32:07 INFO mapreduce.Job:  map 100% reduce 37%
20/11/10 14:32:08 INFO mapreduce.Job:  map 100% reduce 38%
20/11/10 14:32:09 INFO mapreduce.Job:  map 100% reduce 39%
20/11/10 14:32:10 INFO mapreduce.Job:  map 100% reduce 43%
20/11/10 14:32:11 INFO mapreduce.Job:  map 100% reduce 45%
20/11/10 14:32:12 INFO mapreduce.Job:  map 100% reduce 51%
20/11/10 14:32:13 INFO mapreduce.Job:  map 100% reduce 58%
20/11/10 14:32:14 INFO mapreduce.Job:  map 100% reduce 61%
20/11/10 14:32:15 INFO mapreduce.Job:  map 100% reduce 68%
20/11/10 14:32:16 INFO mapreduce.Job:  map 100% reduce 73%
20/11/10 14:32:17 INFO mapreduce.Job:  map 100% reduce 75%
20/11/10 14:32:18 INFO mapreduce.Job:  map 100% reduce 79%
20/11/10 14:32:19 INFO mapreduce.Job:  map 100% reduce 84%
20/11/10 14:32:20 INFO mapreduce.Job:  map 100% reduce 85%
20/11/10 14:32:21 INFO mapreduce.Job:  map 100% reduce 88%
20/11/10 14:32:22 INFO mapreduce.Job:  map 100% reduce 89%
20/11/10 14:32:23 INFO mapreduce.Job:  map 100% reduce 90%
20/11/10 14:32:24 INFO mapreduce.Job:  map 100% reduce 91%
20/11/10 14:32:25 INFO mapreduce.Job:  map 100% reduce 92%
20/11/10 14:32:27 INFO mapreduce.Job:  map 100% reduce 93%
20/11/10 14:32:28 INFO mapreduce.Job:  map 100% reduce 94%
20/11/10 14:32:30 INFO mapreduce.Job:  map 100% reduce 95%
20/11/10 14:32:32 INFO mapreduce.Job:  map 100% reduce 96%
20/11/10 14:32:33 INFO mapreduce.Job:  map 100% reduce 97%
20/11/10 14:32:39 INFO mapreduce.Job:  map 100% reduce 98%
20/11/10 14:32:41 INFO mapreduce.Job:  map 100% reduce 99%
20/11/10 14:32:48 INFO mapreduce.Job:  map 100% reduce 100%
20/11/10 14:32:54 INFO mapreduce.Job: Job job_1603168482046_0034 completed successfully
20/11/10 14:32:55 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=31200292918
		FILE: Number of bytes written=62455460214
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=30000047488
		HDFS: Number of bytes written=30000000000
		HDFS: Number of read operations=1524
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=120
	Job Counters 
		Launched map tasks=448
		Launched reduce tasks=60
		Data-local map tasks=437
		Rack-local map tasks=11
		Total time spent by all maps in occupied slots (ms)=5721686
		Total time spent by all reduces in occupied slots (ms)=3490285
		Total time spent by all map tasks (ms)=5721686
		Total time spent by all reduce tasks (ms)=3490285
		Total vcore-seconds taken by all map tasks=5721686
		Total vcore-seconds taken by all reduce tasks=3490285
		Total megabyte-seconds taken by all map tasks=5859006464
		Total megabyte-seconds taken by all reduce tasks=3574051840
	Map-Reduce Framework
		Map input records=300000000
		Map output records=300000000
		Map output bytes=30600000000
		Map output materialized bytes=31200161280
		Input split bytes=47488
		Combine input records=0
		Combine output records=0
		Reduce input groups=300000000
		Reduce shuffle bytes=31200161280
		Reduce input records=300000000
		Reduce output records=300000000
		Spilled Records=600000000
		Shuffled Maps =26880
		Failed Shuffles=0
		Merged Map outputs=26880
		GC time elapsed (ms)=127264
		CPU time spent (ms)=3402230
		Physical memory (bytes) snapshot=133568618496
		Virtual memory (bytes) snapshot=528306016256
		Total committed heap usage (bytes)=101037637632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=30000000000
	File Output Format Counters 
		Bytes Written=30000000000
20/11/10 14:32:55 INFO terasort.TeraSort: done

real	3m17.207s
user	0m9.321s
sys	0m0.776s
slave20:
slave1:
slave17:
slave15:
slave3:
slave18:
slave2:
slave19:
slave5:
slave16:
slave13:
slave4:
slave10:
slave6:
slave12:
slave11:
    Minion did not return. [Not connected]
slave9:
    Minion did not return. [Not connected]
slave14:
    Minion did not return. [Not connected]
slave8:
    Minion did not return. [Not connected]
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
20/11/10 14:37:55 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
20/11/10 14:37:55 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
rmr: `/terasort-output/0': Input/output error
rmr: File does not exist: hdfs://master:9000/terasort-output/0
20/11/10 14:37:57 INFO terasort.TeraSort: starting
20/11/10 14:37:57 INFO terasort.TeraSort: starting
20/11/10 14:37:57 INFO terasort.TeraSort: starting
20/11/10 14:37:58 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 14:37:58 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 14:37:58 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 14:37:59 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4360465): File does not exist. Holder DFSClient_NONMAPREDUCE_-219368092_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 14:37:59 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4360465): File does not exist. Holder DFSClient_NONMAPREDUCE_-219368092_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

20/11/10 14:37:59 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4360466): File does not exist. Holder DFSClient_NONMAPREDUCE_-406640035_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 14:37:59 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4360466): File does not exist. Holder DFSClient_NONMAPREDUCE_-406640035_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)


real	0m3.410s
user	0m5.180s
sys	0m0.376s

real	0m3.456s
user	0m5.452s
sys	0m0.380s
20/11/10 14:38:00 INFO client.RMProxy: Connecting to ResourceManager at master/10.0.0.27:8032
20/11/10 14:38:01 INFO mapreduce.JobSubmitter: number of splits:448
20/11/10 14:38:01 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
20/11/10 14:38:01 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
20/11/10 14:38:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1603168482046_0035
20/11/10 14:38:01 INFO impl.YarnClientImpl: Submitted application application_1603168482046_0035
20/11/10 14:38:01 INFO mapreduce.Job: The url to track the job: http://master:50030/proxy/application_1603168482046_0035/
20/11/10 14:38:01 INFO mapreduce.Job: Running job: job_1603168482046_0035
20/11/10 14:38:12 INFO mapreduce.Job: Job job_1603168482046_0035 running in uber mode : false
20/11/10 14:38:12 INFO mapreduce.Job:  map 0% reduce 0%
20/11/10 14:38:21 INFO mapreduce.Job:  map 1% reduce 0%
20/11/10 14:38:23 INFO mapreduce.Job:  map 2% reduce 0%
20/11/10 14:38:25 INFO mapreduce.Job:  map 3% reduce 0%
20/11/10 14:38:26 INFO mapreduce.Job:  map 4% reduce 0%
20/11/10 14:38:27 INFO mapreduce.Job:  map 6% reduce 0%
20/11/10 14:38:28 INFO mapreduce.Job:  map 10% reduce 0%
20/11/10 14:38:29 INFO mapreduce.Job:  map 13% reduce 0%
20/11/10 14:38:30 INFO mapreduce.Job:  map 15% reduce 0%
20/11/10 14:38:31 INFO mapreduce.Job:  map 16% reduce 0%
20/11/10 14:38:32 INFO mapreduce.Job:  map 17% reduce 0%
20/11/10 14:38:33 INFO mapreduce.Job:  map 18% reduce 0%
20/11/10 14:38:34 INFO mapreduce.Job:  map 19% reduce 0%
20/11/10 14:38:35 INFO mapreduce.Job:  map 21% reduce 0%
20/11/10 14:38:37 INFO mapreduce.Job:  map 24% reduce 0%
20/11/10 14:38:38 INFO mapreduce.Job:  map 27% reduce 0%
20/11/10 14:38:39 INFO mapreduce.Job:  map 30% reduce 0%
20/11/10 14:38:40 INFO mapreduce.Job:  map 33% reduce 0%
20/11/10 14:38:41 INFO mapreduce.Job:  map 35% reduce 0%
20/11/10 14:38:42 INFO mapreduce.Job:  map 37% reduce 0%
20/11/10 14:38:43 INFO mapreduce.Job:  map 39% reduce 0%
20/11/10 14:38:44 INFO mapreduce.Job:  map 41% reduce 0%
20/11/10 14:38:45 INFO mapreduce.Job:  map 42% reduce 0%
20/11/10 14:38:46 INFO mapreduce.Job:  map 43% reduce 0%
20/11/10 14:38:47 INFO mapreduce.Job:  map 47% reduce 0%
20/11/10 14:38:48 INFO mapreduce.Job:  map 49% reduce 0%
20/11/10 14:38:49 INFO mapreduce.Job:  map 52% reduce 0%
20/11/10 14:38:50 INFO mapreduce.Job:  map 54% reduce 0%
20/11/10 14:38:51 INFO mapreduce.Job:  map 56% reduce 0%
20/11/10 14:38:52 INFO mapreduce.Job:  map 59% reduce 0%
20/11/10 14:38:53 INFO mapreduce.Job:  map 61% reduce 0%
20/11/10 14:38:54 INFO mapreduce.Job:  map 62% reduce 0%
20/11/10 14:38:55 INFO mapreduce.Job:  map 63% reduce 0%
20/11/10 14:38:56 INFO mapreduce.Job:  map 64% reduce 0%
20/11/10 14:38:57 INFO mapreduce.Job:  map 65% reduce 0%
20/11/10 14:38:58 INFO mapreduce.Job:  map 68% reduce 0%
20/11/10 14:38:59 INFO mapreduce.Job:  map 69% reduce 0%
20/11/10 14:39:00 INFO mapreduce.Job:  map 70% reduce 0%
20/11/10 14:39:02 INFO mapreduce.Job:  map 74% reduce 0%
20/11/10 14:39:03 INFO mapreduce.Job:  map 75% reduce 0%
20/11/10 14:39:04 INFO mapreduce.Job:  map 76% reduce 0%
20/11/10 14:39:05 INFO mapreduce.Job:  map 79% reduce 0%
20/11/10 14:39:06 INFO mapreduce.Job:  map 80% reduce 0%
20/11/10 14:39:07 INFO mapreduce.Job:  map 81% reduce 0%
20/11/10 14:39:09 INFO mapreduce.Job:  map 82% reduce 0%
20/11/10 14:39:10 INFO mapreduce.Job:  map 83% reduce 0%
20/11/10 14:39:11 INFO mapreduce.Job:  map 85% reduce 0%
20/11/10 14:39:12 INFO mapreduce.Job:  map 86% reduce 0%
20/11/10 14:39:14 INFO mapreduce.Job:  map 87% reduce 0%
20/11/10 14:39:15 INFO mapreduce.Job:  map 88% reduce 0%
20/11/10 14:39:16 INFO mapreduce.Job:  map 89% reduce 0%
20/11/10 14:39:17 INFO mapreduce.Job:  map 90% reduce 0%
20/11/10 14:39:18 INFO mapreduce.Job:  map 91% reduce 0%
20/11/10 14:39:19 INFO mapreduce.Job:  map 92% reduce 0%
20/11/10 14:39:21 INFO mapreduce.Job:  map 93% reduce 0%
20/11/10 14:39:25 INFO mapreduce.Job:  map 94% reduce 0%
20/11/10 14:39:26 INFO mapreduce.Job:  map 95% reduce 0%
20/11/10 14:39:27 INFO mapreduce.Job:  map 96% reduce 0%
20/11/10 14:39:29 INFO mapreduce.Job:  map 97% reduce 0%
20/11/10 14:39:31 INFO mapreduce.Job:  map 98% reduce 0%
20/11/10 14:39:34 INFO mapreduce.Job:  map 99% reduce 0%
20/11/10 14:39:38 INFO mapreduce.Job:  map 100% reduce 0%
20/11/10 14:39:55 INFO mapreduce.Job:  map 100% reduce 2%
20/11/10 14:39:56 INFO mapreduce.Job:  map 100% reduce 4%
20/11/10 14:39:57 INFO mapreduce.Job:  map 100% reduce 6%
20/11/10 14:39:58 INFO mapreduce.Job:  map 100% reduce 8%
20/11/10 14:39:59 INFO mapreduce.Job:  map 100% reduce 9%
20/11/10 14:40:00 INFO mapreduce.Job:  map 100% reduce 10%
20/11/10 14:40:01 INFO mapreduce.Job:  map 100% reduce 11%
20/11/10 14:40:02 INFO mapreduce.Job:  map 100% reduce 12%
20/11/10 14:40:04 INFO mapreduce.Job:  map 100% reduce 13%
20/11/10 14:40:05 INFO mapreduce.Job:  map 100% reduce 14%
20/11/10 14:40:06 INFO mapreduce.Job:  map 100% reduce 15%
20/11/10 14:40:07 INFO mapreduce.Job:  map 100% reduce 16%
20/11/10 14:40:08 INFO mapreduce.Job:  map 100% reduce 17%
20/11/10 14:40:09 INFO mapreduce.Job:  map 100% reduce 18%
20/11/10 14:40:10 INFO mapreduce.Job:  map 100% reduce 19%
20/11/10 14:40:11 INFO mapreduce.Job:  map 100% reduce 20%
20/11/10 14:40:12 INFO mapreduce.Job:  map 100% reduce 21%
20/11/10 14:40:14 INFO mapreduce.Job:  map 100% reduce 22%
20/11/10 14:40:15 INFO mapreduce.Job:  map 100% reduce 23%
20/11/10 14:40:17 INFO mapreduce.Job:  map 100% reduce 24%
20/11/10 14:40:18 INFO mapreduce.Job:  map 100% reduce 25%
20/11/10 14:40:19 INFO mapreduce.Job:  map 100% reduce 26%
20/11/10 14:40:20 INFO mapreduce.Job:  map 100% reduce 28%
20/11/10 14:40:22 INFO mapreduce.Job:  map 100% reduce 29%
20/11/10 14:40:23 INFO mapreduce.Job:  map 100% reduce 30%
20/11/10 14:40:25 INFO mapreduce.Job:  map 100% reduce 31%
20/11/10 14:40:32 INFO mapreduce.Job:  map 100% reduce 34%
20/11/10 14:40:35 INFO mapreduce.Job:  map 100% reduce 60%
20/11/10 14:40:38 INFO mapreduce.Job:  map 100% reduce 75%
20/11/10 14:40:39 INFO mapreduce.Job:  map 100% reduce 76%
20/11/10 14:40:42 INFO mapreduce.Job:  map 100% reduce 82%
20/11/10 14:40:43 INFO mapreduce.Job:  map 100% reduce 83%
20/11/10 14:40:45 INFO mapreduce.Job:  map 100% reduce 88%
20/11/10 14:40:48 INFO mapreduce.Job:  map 100% reduce 92%
20/11/10 14:40:51 INFO mapreduce.Job:  map 100% reduce 96%
20/11/10 14:40:54 INFO mapreduce.Job:  map 100% reduce 97%
20/11/10 14:40:56 INFO mapreduce.Job:  map 100% reduce 98%
20/11/10 14:40:59 INFO mapreduce.Job:  map 100% reduce 99%
20/11/10 14:41:05 INFO mapreduce.Job:  map 100% reduce 100%
20/11/10 14:41:17 INFO mapreduce.Job: Job job_1603168482046_0035 completed successfully
20/11/10 14:41:18 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=31200292918
		FILE: Number of bytes written=62455460214
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=30000047488
		HDFS: Number of bytes written=30000000000
		HDFS: Number of read operations=1524
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=120
	Job Counters 
		Launched map tasks=448
		Launched reduce tasks=60
		Data-local map tasks=434
		Rack-local map tasks=14
		Total time spent by all maps in occupied slots (ms)=5829752
		Total time spent by all reduces in occupied slots (ms)=3773601
		Total time spent by all map tasks (ms)=5829752
		Total time spent by all reduce tasks (ms)=3773601
		Total vcore-seconds taken by all map tasks=5829752
		Total vcore-seconds taken by all reduce tasks=3773601
		Total megabyte-seconds taken by all map tasks=5969666048
		Total megabyte-seconds taken by all reduce tasks=3864167424
	Map-Reduce Framework
		Map input records=300000000
		Map output records=300000000
		Map output bytes=30600000000
		Map output materialized bytes=31200161280
		Input split bytes=47488
		Combine input records=0
		Combine output records=0
		Reduce input groups=300000000
		Reduce shuffle bytes=31200161280
		Reduce input records=300000000
		Reduce output records=300000000
		Spilled Records=600000000
		Shuffled Maps =26880
		Failed Shuffles=0
		Merged Map outputs=26880
		GC time elapsed (ms)=122715
		CPU time spent (ms)=3421780
		Physical memory (bytes) snapshot=133366009856
		Virtual memory (bytes) snapshot=528288407552
		Total committed heap usage (bytes)=101022433280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=30000000000
	File Output Format Counters 
		Bytes Written=30000000000
20/11/10 14:41:18 INFO terasort.TeraSort: done

real	3m22.270s
user	0m9.273s
sys	0m0.696s
slave20:
slave1:
slave3:
slave17:
slave15:
slave18:
slave19:
slave2:
slave5:
slave16:
slave12:
slave4:
slave10:
slave6:
slave13:
Exiting on Ctrl-C
This job's jid is:
20201110145422101529
The minions may not have all finished running and any remaining minions will return upon completion. To look up the return data for this job later run:
salt-run jobs.lookup_jid 20201110145422101529
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
rmr: DEPRECATED: Please use 'rm -r' instead.
20/11/10 14:54:26 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
rmr: File does not exist: hdfs://master:9000/terasort-output/0
rmr: File does not exist: hdfs://master:9000/terasort-output/0
20/11/10 14:54:28 INFO terasort.TeraSort: starting
20/11/10 14:54:28 INFO terasort.TeraSort: starting
20/11/10 14:54:28 INFO terasort.TeraSort: starting
20/11/10 14:54:29 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 14:54:29 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 14:54:29 INFO input.FileInputFormat: Total input paths to process : 2
20/11/10 14:54:30 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4360606): File does not exist. Holder DFSClient_NONMAPREDUCE_-215741987_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 14:54:30 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4360606): File does not exist. Holder DFSClient_NONMAPREDUCE_-215741987_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

20/11/10 14:54:30 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /terasort-output/0/_partition.lst (inode 4360605): File does not exist. Holder DFSClient_NONMAPREDUCE_1567280614_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy9.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
20/11/10 14:54:30 ERROR terasort.TeraSort: No lease on /terasort-output/0/_partition.lst (inode 4360605): File does not exist. Holder DFSClient_NONMAPREDUCE_1567280614_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3516)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)


real	0m3.497s
user	0m5.264s
sys	0m0.392s

real	0m3.522s
user	0m5.476s
sys	0m0.400s
20/11/10 14:54:31 INFO client.RMProxy: Connecting to ResourceManager at master/10.0.0.27:8032
20/11/10 14:54:32 INFO mapreduce.JobSubmitter: number of splits:448
20/11/10 14:54:32 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
20/11/10 14:54:32 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
20/11/10 14:54:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1603168482046_0036
20/11/10 14:54:33 INFO impl.YarnClientImpl: Submitted application application_1603168482046_0036
20/11/10 14:54:33 INFO mapreduce.Job: The url to track the job: http://master:50030/proxy/application_1603168482046_0036/
20/11/10 14:54:33 INFO mapreduce.Job: Running job: job_1603168482046_0036
20/11/10 14:54:45 INFO mapreduce.Job: Job job_1603168482046_0036 running in uber mode : false
20/11/10 14:54:45 INFO mapreduce.Job:  map 0% reduce 0%
20/11/10 14:54:54 INFO mapreduce.Job:  map 1% reduce 0%
20/11/10 14:54:56 INFO mapreduce.Job:  map 2% reduce 0%
20/11/10 14:54:58 INFO mapreduce.Job:  map 3% reduce 0%
20/11/10 14:54:59 INFO mapreduce.Job:  map 4% reduce 0%
20/11/10 14:55:00 INFO mapreduce.Job:  map 5% reduce 0%
20/11/10 14:55:01 INFO mapreduce.Job:  map 8% reduce 0%
20/11/10 14:55:02 INFO mapreduce.Job:  map 11% reduce 0%
20/11/10 14:55:03 INFO mapreduce.Job:  map 13% reduce 0%
20/11/10 14:55:04 INFO mapreduce.Job:  map 16% reduce 0%
20/11/10 14:55:05 INFO mapreduce.Job:  map 18% reduce 0%
20/11/10 14:55:06 INFO mapreduce.Job:  map 19% reduce 0%
20/11/10 14:55:07 INFO mapreduce.Job:  map 21% reduce 0%
20/11/10 14:55:08 INFO mapreduce.Job:  map 22% reduce 0%
20/11/10 14:55:09 INFO mapreduce.Job:  map 23% reduce 0%
20/11/10 14:55:11 INFO mapreduce.Job:  map 24% reduce 0%
20/11/10 14:55:12 INFO mapreduce.Job:  map 27% reduce 0%
20/11/10 14:55:13 INFO mapreduce.Job:  map 29% reduce 0%
20/11/10 14:55:14 INFO mapreduce.Job:  map 31% reduce 0%
20/11/10 14:55:15 INFO mapreduce.Job:  map 36% reduce 0%
20/11/10 14:55:17 INFO mapreduce.Job:  map 39% reduce 0%
20/11/10 14:55:18 INFO mapreduce.Job:  map 40% reduce 0%
20/11/10 14:55:20 INFO mapreduce.Job:  map 43% reduce 0%
20/11/10 14:55:22 INFO mapreduce.Job:  map 46% reduce 0%
20/11/10 14:55:23 INFO mapreduce.Job:  map 47% reduce 0%
20/11/10 14:55:27 INFO mapreduce.Job:  map 51% reduce 0%
20/11/10 14:55:29 INFO mapreduce.Job:  map 59% reduce 0%
20/11/10 14:55:30 INFO mapreduce.Job:  map 60% reduce 0%
20/11/10 14:55:33 INFO mapreduce.Job:  map 63% reduce 0%
20/11/10 14:55:35 INFO mapreduce.Job:  map 66% reduce 0%
20/11/10 14:55:36 INFO mapreduce.Job:  map 68% reduce 0%
20/11/10 14:55:38 INFO mapreduce.Job:  map 69% reduce 0%
20/11/10 14:55:39 INFO mapreduce.Job:  map 70% reduce 0%
20/11/10 14:55:40 INFO mapreduce.Job:  map 72% reduce 0%
20/11/10 14:55:41 INFO mapreduce.Job:  map 74% reduce 0%
20/11/10 14:55:43 INFO mapreduce.Job:  map 76% reduce 0%
20/11/10 14:55:44 INFO mapreduce.Job:  map 77% reduce 0%
20/11/10 14:55:45 INFO mapreduce.Job:  map 79% reduce 0%
20/11/10 14:55:46 INFO mapreduce.Job:  map 80% reduce 0%
20/11/10 14:55:48 INFO mapreduce.Job:  map 82% reduce 0%
20/11/10 14:55:55 INFO mapreduce.Job:  map 85% reduce 0%
20/11/10 14:55:57 INFO mapreduce.Job:  map 87% reduce 0%
20/11/10 14:55:58 INFO mapreduce.Job:  map 91% reduce 0%
20/11/10 14:56:01 INFO mapreduce.Job:  map 92% reduce 0%
20/11/10 14:56:02 INFO mapreduce.Job:  map 93% reduce 0%
20/11/10 14:56:04 INFO mapreduce.Job:  map 94% reduce 0%
20/11/10 14:56:05 INFO mapreduce.Job:  map 95% reduce 0%
20/11/10 14:56:06 INFO mapreduce.Job:  map 96% reduce 0%
20/11/10 14:56:07 INFO mapreduce.Job:  map 97% reduce 0%
20/11/10 14:56:10 INFO mapreduce.Job:  map 98% reduce 0%
20/11/10 14:56:14 INFO mapreduce.Job:  map 99% reduce 0%
20/11/10 14:56:18 INFO mapreduce.Job:  map 100% reduce 0%
20/11/10 14:56:33 INFO mapreduce.Job:  map 100% reduce 2%
20/11/10 14:56:34 INFO mapreduce.Job:  map 100% reduce 4%
20/11/10 14:56:35 INFO mapreduce.Job:  map 100% reduce 6%
20/11/10 14:56:36 INFO mapreduce.Job:  map 100% reduce 8%
20/11/10 14:56:37 INFO mapreduce.Job:  map 100% reduce 9%
20/11/10 14:56:38 INFO mapreduce.Job:  map 100% reduce 10%
20/11/10 14:56:39 INFO mapreduce.Job:  map 100% reduce 11%
20/11/10 14:56:40 INFO mapreduce.Job:  map 100% reduce 12%
20/11/10 14:56:41 INFO mapreduce.Job:  map 100% reduce 13%
20/11/10 14:56:42 INFO mapreduce.Job:  map 100% reduce 14%
20/11/10 14:56:43 INFO mapreduce.Job:  map 100% reduce 15%
20/11/10 14:56:44 INFO mapreduce.Job:  map 100% reduce 16%
20/11/10 14:56:45 INFO mapreduce.Job:  map 100% reduce 17%
20/11/10 14:56:46 INFO mapreduce.Job:  map 100% reduce 18%
20/11/10 14:56:48 INFO mapreduce.Job:  map 100% reduce 20%
20/11/10 14:56:50 INFO mapreduce.Job:  map 100% reduce 21%
20/11/10 14:56:51 INFO mapreduce.Job:  map 100% reduce 22%
20/11/10 14:56:52 INFO mapreduce.Job:  map 100% reduce 23%
20/11/10 14:56:53 INFO mapreduce.Job:  map 100% reduce 24%
20/11/10 14:56:54 INFO mapreduce.Job:  map 100% reduce 25%
20/11/10 14:56:55 INFO mapreduce.Job:  map 100% reduce 26%
20/11/10 14:56:57 INFO mapreduce.Job:  map 100% reduce 27%
20/11/10 14:56:58 INFO mapreduce.Job:  map 100% reduce 28%
20/11/10 14:57:00 INFO mapreduce.Job:  map 100% reduce 29%
20/11/10 14:57:01 INFO mapreduce.Job:  map 100% reduce 30%
20/11/10 14:57:02 INFO mapreduce.Job:  map 100% reduce 31%
20/11/10 14:57:03 INFO mapreduce.Job:  map 100% reduce 33%
20/11/10 14:57:04 INFO mapreduce.Job:  map 100% reduce 35%
20/11/10 14:57:05 INFO mapreduce.Job:  map 100% reduce 37%
20/11/10 14:57:06 INFO mapreduce.Job:  map 100% reduce 40%
20/11/10 14:57:07 INFO mapreduce.Job:  map 100% reduce 45%
20/11/10 14:57:08 INFO mapreduce.Job:  map 100% reduce 46%
20/11/10 14:57:09 INFO mapreduce.Job:  map 100% reduce 48%
20/11/10 14:57:10 INFO mapreduce.Job:  map 100% reduce 51%
20/11/10 14:57:11 INFO mapreduce.Job:  map 100% reduce 54%
20/11/10 14:57:12 INFO mapreduce.Job:  map 100% reduce 62%
20/11/10 14:57:14 INFO mapreduce.Job:  map 100% reduce 76%
20/11/10 14:57:15 INFO mapreduce.Job:  map 100% reduce 78%
20/11/10 14:57:17 INFO mapreduce.Job:  map 100% reduce 82%
20/11/10 14:57:19 INFO mapreduce.Job:  map 100% reduce 83%
20/11/10 14:57:20 INFO mapreduce.Job:  map 100% reduce 85%
20/11/10 14:57:22 INFO mapreduce.Job:  map 100% reduce 87%
20/11/10 14:57:23 INFO mapreduce.Job:  map 100% reduce 90%
20/11/10 14:57:27 INFO mapreduce.Job:  map 100% reduce 94%
20/11/10 14:57:28 INFO mapreduce.Job:  map 100% reduce 95%
20/11/10 14:57:30 INFO mapreduce.Job:  map 100% reduce 98%
20/11/10 14:57:33 INFO mapreduce.Job:  map 100% reduce 99%
20/11/10 14:57:37 INFO mapreduce.Job:  map 100% reduce 100%
20/11/10 14:57:48 INFO mapreduce.Job: Job job_1603168482046_0036 completed successfully
20/11/10 14:57:48 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=31200292918
		FILE: Number of bytes written=62455460214
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=30000047488
		HDFS: Number of bytes written=30000000000
		HDFS: Number of read operations=1524
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=120
	Job Counters 
		Launched map tasks=448
		Launched reduce tasks=60
		Data-local map tasks=432
		Rack-local map tasks=16
		Total time spent by all maps in occupied slots (ms)=6466002
		Total time spent by all reduces in occupied slots (ms)=3686669
		Total time spent by all map tasks (ms)=6466002
		Total time spent by all reduce tasks (ms)=3686669
		Total vcore-seconds taken by all map tasks=6466002
		Total vcore-seconds taken by all reduce tasks=3686669
		Total megabyte-seconds taken by all map tasks=6621186048
		Total megabyte-seconds taken by all reduce tasks=3775149056
	Map-Reduce Framework
		Map input records=300000000
		Map output records=300000000
		Map output bytes=30600000000
		Map output materialized bytes=31200161280
		Input split bytes=47488
		Combine input records=0
		Combine output records=0
		Reduce input groups=300000000
		Reduce shuffle bytes=31200161280
		Reduce input records=300000000
		Reduce output records=300000000
		Spilled Records=600000000
		Shuffled Maps =26880
		Failed Shuffles=0
		Merged Map outputs=26880
		GC time elapsed (ms)=119206
		CPU time spent (ms)=3438720
		Physical memory (bytes) snapshot=133126180864
		Virtual memory (bytes) snapshot=528316170240
		Total committed heap usage (bytes)=100971053056
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=30000000000
	File Output Format Counters 
		Bytes Written=30000000000
20/11/10 14:57:48 INFO terasort.TeraSort: done

real	3m21.966s
user	0m9.489s
sys	0m0.756s
